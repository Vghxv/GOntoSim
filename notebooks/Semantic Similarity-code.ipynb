{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import Libraries\n",
    "\n",
    "from goatools.base import get_godag\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "\n",
    "# import annotations\n",
    "from ALL_EC_GOTERMS_IEA_MF import *\n",
    "from ALL_EC_GOTERMS_NonIEA_MF import *\n",
    "from ALL_EC_GOTERMS_IEA_BP import *\n",
    "from ALL_EC_GOTERMS_NonIEA_BP import *\n",
    "\n",
    "# define named tuple\n",
    "Gene = namedtuple(\"Gene\", \"GeneName GOAnnotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2024-06-17) 45,494 Terms; optional_attrs(relationship)\n"
     ]
    }
   ],
   "source": [
    "# load Gene Ontology\n",
    "go = get_godag(\"go-basic.obo\", optional_attrs={\"relationship\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Relationship Semantic Contribution\n",
    "is_a = 0.8\n",
    "part_of = 0.6\n",
    "regulates = 0.7\n",
    "negatively_regulates = 0.7\n",
    "positively_regulates = 0.7\n",
    "reg = \"reg0.7\"\n",
    "c = 0.67  # for GOGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions\n",
    "def all_common_parent_go_ids(goids, godag):\n",
    "    \"\"\"\n",
    "    This function finds the common ancestors in the GO\n",
    "    tree of the list of goids in the input.\n",
    "    \"\"\"\n",
    "    # Find candidates from first\n",
    "    rec = godag[goids[0]]\n",
    "    candidates = rec.get_all_upper()\n",
    "    candidates.update({goids[0]})\n",
    "\n",
    "    # Find intersection with second to nth goid\n",
    "    for goid in goids[1:]:\n",
    "        rec = godag[goid]\n",
    "        parents = rec.get_all_upper()\n",
    "        parents.update({goid})\n",
    "\n",
    "        # Find the intersection with the candidates, and update.\n",
    "        candidates.intersection_update(parents)\n",
    "    return candidates\n",
    "\n",
    "\n",
    "def lowest_common_ancestor(goterms, godag):\n",
    "    \"\"\"\n",
    "    This function gets the nearest common ancestor\n",
    "    using the above function.\n",
    "    Only returns single most specific - assumes unique exists.\n",
    "    \"\"\"\n",
    "    # Take the element at maximum depth.\n",
    "    return max(all_common_parent_go_ids(goterms, godag), key=lambda t: godag[t].depth)\n",
    "\n",
    "\n",
    "def all_paths_to_top(term, godag):\n",
    "    # inputs: term_id and Go dag with 'relationship' as optional attributes\n",
    "    \"\"\"Returns all possible paths to the root node\"\"\"\n",
    "    if term not in godag:\n",
    "        sys.stderr.write(\"Term %s not found!\\n\" % term)\n",
    "        return\n",
    "\n",
    "    def _all_paths_to_top_recursive(rec):\n",
    "        if rec.level == 0:\n",
    "            return [[rec]]\n",
    "        paths = []\n",
    "        parents = rec.get_goterms_upper()\n",
    "        for parent in parents:\n",
    "            top_paths = _all_paths_to_top_recursive(parent)\n",
    "            for top_path in top_paths:\n",
    "                top_path.append(rec)\n",
    "                paths.append(top_path)\n",
    "        return paths\n",
    "\n",
    "    go_term = godag[term]\n",
    "    return _all_paths_to_top_recursive(go_term)\n",
    "\n",
    "\n",
    "def all_paths_to_top_wang(term, godag, optional_relationships):\n",
    "    # inputs: term_id and Go dag with 'relationship' as optional attributes\n",
    "    \"\"\"Returns all possible paths to the root node\"\"\"\n",
    "    if term not in godag:\n",
    "        sys.stderr.write(\"Term %s not found!\\n\" % term)\n",
    "        return\n",
    "\n",
    "    def _all_paths_to_top_recursive(rec):\n",
    "        if rec.level == 0:\n",
    "            return [[rec]]\n",
    "        paths = []\n",
    "        parents = rec.get_goterms_upper_rels(optional_relationships)\n",
    "        # parents = rec.get_goterms_upper()\n",
    "        for parent in parents:\n",
    "            # parent = go[parent1]\n",
    "            top_paths = _all_paths_to_top_recursive(parent)\n",
    "            for top_path in top_paths:\n",
    "                top_path.append(rec)\n",
    "                paths.append(top_path)\n",
    "        return paths\n",
    "\n",
    "    go_term = godag[term]\n",
    "    return _all_paths_to_top_recursive(go_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Semantic_Value(go_id, go, method):\n",
    "    \"\"\"input: goterm_id\n",
    "    returns all of the weighted (all relatinships in go-basic) paths to root\n",
    "    #relationship types are global variables with appropriate weights\n",
    "    \"\"\"\n",
    "    if method == \"wang\":\n",
    "        # calculates all paths to top (with all relationships)\n",
    "        optional_relationships = {\"part_of\"}\n",
    "        all_all_paths = all_paths_to_top_wang(go_id, go, optional_relationships)\n",
    "        S_values = list()\n",
    "        for index, path in enumerate(all_all_paths):\n",
    "            S_values.append([])\n",
    "            # print(\"index = \" + str(index))\n",
    "            path.reverse()\n",
    "            for idx, term in enumerate(path):\n",
    "                # Semantic Value of the term itself is always 1\n",
    "                if idx == 0:  # which is on idx = 0\n",
    "                    S_values[index].append((go_id, 1))\n",
    "                if idx < len(path) - 1:\n",
    "                    if term.relationship != {}:\n",
    "                        # print(term.relationship.keys())\n",
    "                        if \"part_of\" in term.relationship:\n",
    "                            if path[idx + 1] in term.relationship[\"part_of\"]:\n",
    "                                S_values[index].append(\n",
    "                                    (\n",
    "                                        path[idx + 1].item_id,\n",
    "                                        S_values[index][idx][1] * part_of,\n",
    "                                    )\n",
    "                                )\n",
    "                            else:\n",
    "                                S_values[index].append(\n",
    "                                    (\n",
    "                                        path[idx + 1].item_id,\n",
    "                                        S_values[index][idx][1] * is_a,\n",
    "                                    )\n",
    "                                )\n",
    "                        else:\n",
    "                            S_values[index].append(\n",
    "                                (path[idx + 1].item_id, S_values[index][idx][1] * is_a)\n",
    "                            )\n",
    "                    else:\n",
    "                        S_values[index].append(\n",
    "                            (path[idx + 1].item_id, S_values[index][idx][1] * is_a)\n",
    "                        )\n",
    "        return final_values(S_values, \"max\")\n",
    "    elif method == \"GOGO\":\n",
    "        optional_relationships = {\"part_of\"}\n",
    "        all_all_paths = all_paths_to_top_wang(go_id, go, optional_relationships)\n",
    "        S_values = list()\n",
    "        for index, path in enumerate(all_all_paths):\n",
    "            S_values.append([])\n",
    "            # print(\"index = \" + str(index))\n",
    "            path.reverse()\n",
    "            for idx, term in enumerate(path):\n",
    "                # Semantic Value of the term itself is always 1\n",
    "                if idx == 0:  # which is on idx = 0\n",
    "                    S_values[index].append((go_id, 1))\n",
    "                if idx < len(path) - 1:\n",
    "                    if term.relationship != {}:\n",
    "                        # print(term.relationship.keys())\n",
    "                        if \"part_of\" in term.relationship:\n",
    "                            if path[idx + 1] in term.relationship[\"part_of\"]:\n",
    "                                weight = (\n",
    "                                    1 / (c + len(go[path[idx + 1].item_id].children))\n",
    "                                ) + part_of\n",
    "                                S_values[index].append(\n",
    "                                    (\n",
    "                                        path[idx + 1].item_id,\n",
    "                                        S_values[index][idx][1] * weight,\n",
    "                                    )\n",
    "                                )\n",
    "                            else:\n",
    "                                weight = (\n",
    "                                    1 / (c + len(go[path[idx + 1].item_id].children))\n",
    "                                ) + is_a\n",
    "                                S_values[index].append(\n",
    "                                    (\n",
    "                                        path[idx + 1].item_id,\n",
    "                                        S_values[index][idx][1] * weight,\n",
    "                                    )\n",
    "                                )\n",
    "                        else:\n",
    "                            weight = (\n",
    "                                1 / (c + len(go[path[idx + 1].item_id].children))\n",
    "                            ) + is_a\n",
    "                            S_values[index].append(\n",
    "                                (\n",
    "                                    path[idx + 1].item_id,\n",
    "                                    S_values[index][idx][1] * weight,\n",
    "                                )\n",
    "                            )\n",
    "                    else:\n",
    "                        weight = (\n",
    "                            1 / (c + len(go[path[idx + 1].item_id].children))\n",
    "                        ) + is_a\n",
    "                        S_values[index].append(\n",
    "                            (path[idx + 1].item_id, S_values[index][idx][1] * weight)\n",
    "                        )\n",
    "        return final_values(S_values, \"max\")\n",
    "    # Baseline Measure - Almost Same as Semantic Value; only Difference is the weight of root as ancestor = 0 and different realtionships\n",
    "    else:\n",
    "        all_all_paths = all_paths_to_top(go_id, go)\n",
    "        S_values = list()\n",
    "        # print(go_id)\n",
    "        for index, path in enumerate(all_all_paths):\n",
    "            S_values.append([])\n",
    "            # print(\"index = \" + str(index))\n",
    "            path.reverse()\n",
    "            for idx, term in enumerate(path):\n",
    "                # Semantic Value of the term itself is always 1\n",
    "                if idx == 0:  # which is on idx = 0\n",
    "                    S_values[index].append((go_id, 1))\n",
    "                if (\n",
    "                    idx < len(path) - 1\n",
    "                    and path[idx + 1].item_id != \"GO:0003674\"\n",
    "                    and path[idx + 1].item_id != \"GO:0005575\"\n",
    "                    and path[idx + 1].item_id != \"GO:0008150\"\n",
    "                ):\n",
    "                    if term.relationship != {}:\n",
    "                        # print(term.relationship.keys())\n",
    "                        if \"part_of\" in term.relationship:\n",
    "                            if path[idx + 1] in term.relationship[\"part_of\"]:\n",
    "                                S_values[index].append(\n",
    "                                    (\n",
    "                                        path[idx + 1].item_id,\n",
    "                                        S_values[index][idx][1] * part_of,\n",
    "                                    )\n",
    "                                )\n",
    "                            else:\n",
    "                                S_values[index].append(\n",
    "                                    (\n",
    "                                        path[idx + 1].item_id,\n",
    "                                        S_values[index][idx][1] * is_a,\n",
    "                                    )\n",
    "                                )\n",
    "                        elif \"regulates\" in term.relationship:\n",
    "                            if path[idx + 1] in term.relationship[\"regulates\"]:\n",
    "                                S_values[index].append(\n",
    "                                    (\n",
    "                                        path[idx + 1].item_id,\n",
    "                                        S_values[index][idx][1] * regulates,\n",
    "                                    )\n",
    "                                )\n",
    "                            else:\n",
    "                                S_values[index].append(\n",
    "                                    (\n",
    "                                        path[idx + 1].item_id,\n",
    "                                        S_values[index][idx][1] * is_a,\n",
    "                                    )\n",
    "                                )\n",
    "                        elif \"negatively_regulates\" in term.relationship:\n",
    "                            if (\n",
    "                                path[idx + 1]\n",
    "                                in term.relationship[\"negatively_regulates\"]\n",
    "                            ):\n",
    "                                S_values[index].append(\n",
    "                                    (\n",
    "                                        path[idx + 1].item_id,\n",
    "                                        S_values[index][idx][1] * negatively_regulates,\n",
    "                                    )\n",
    "                                )\n",
    "                            else:\n",
    "                                S_values[index].append(\n",
    "                                    (\n",
    "                                        path[idx + 1].item_id,\n",
    "                                        S_values[index][idx][1] * is_a,\n",
    "                                    )\n",
    "                                )\n",
    "                        elif \"positively_regulates\" in term.relationship:\n",
    "                            if (\n",
    "                                path[idx + 1]\n",
    "                                in term.relationship[\"positively_regulates\"]\n",
    "                            ):\n",
    "                                S_values[index].append(\n",
    "                                    (\n",
    "                                        path[idx + 1].item_id,\n",
    "                                        S_values[index][idx][1] * positively_regulates,\n",
    "                                    )\n",
    "                                )\n",
    "                            else:\n",
    "                                S_values[index].append(\n",
    "                                    (\n",
    "                                        path[idx + 1].item_id,\n",
    "                                        S_values[index][idx][1] * is_a,\n",
    "                                    )\n",
    "                                )\n",
    "                        else:\n",
    "                            S_values[index].append(\n",
    "                                (path[idx + 1].item_id, S_values[index][idx][1] * is_a)\n",
    "                            )\n",
    "                    else:\n",
    "                        S_values[index].append(\n",
    "                            (path[idx + 1].item_id, S_values[index][idx][1] * is_a)\n",
    "                        )\n",
    "                if (\n",
    "                    term.item_id == \"GO:0003674\"\n",
    "                    or term.item_id == \"GO:0005575\"\n",
    "                    or term.item_id == \"GO:0008150\"\n",
    "                ):\n",
    "                    S_values[index].append((term.item_id, 0))\n",
    "        if method == \"Baseline\":\n",
    "            return final_values(S_values, \"max\")\n",
    "        if method == \"Baseline_LCA\":\n",
    "            svaluesfinal = final_values(S_values, \"max\")\n",
    "            # Replace the max or min s-values in all paths to assign only one value to each node, consistent in all paths\n",
    "            S_values_Modified = list()\n",
    "            for index, path in enumerate(S_values):\n",
    "                S_values_Modified.append([])\n",
    "                for idx, term1 in enumerate(path):\n",
    "                    # \t\tprint(list(value for (term, value) in svaluesfinal if term == term1[0]))\n",
    "                    ind = [value for (term, value) in svaluesfinal if term == term1[0]]\n",
    "                    S_values_Modified[index].append((path[idx][0], ind[0]))\n",
    "            SumOfNodesOnEachPath = list()\n",
    "            for index, path in enumerate(S_values_Modified):\n",
    "                # \tprint(\"Modified index and path: \", index, path)\n",
    "                SumOfNodesOnEachPath.append(sum(x[1] for x in path))\n",
    "            maxPath = SumOfNodesOnEachPath.index(max(SumOfNodesOnEachPath))\n",
    "            return S_values_Modified[maxPath], SumOfNodesOnEachPath[maxPath]\n",
    "\n",
    "\n",
    "def final_values(S_values, isMax):\n",
    "    \"\"\"helper function to assign the max of the weights assigned to each term\"\"\"\n",
    "    # S_values = sorted(S_values, key=lambda x: x[0])\n",
    "    unique_terms_s_values = []\n",
    "    for path in S_values:\n",
    "        for term in path:\n",
    "            unique_terms_s_values.append(term)\n",
    "    unique_terms_s_values = sorted(unique_terms_s_values, key=lambda x: x[0])\n",
    "    _s_values = {}\n",
    "    for y, x in unique_terms_s_values:\n",
    "        if y in _s_values:\n",
    "            _s_values[y].append((y, x))\n",
    "        else:\n",
    "            _s_values[y] = [(y, x)]\n",
    "    final_s_values = []\n",
    "    if isMax == \"max\":\n",
    "        for node in _s_values:\n",
    "            final_s_values.append(max(_s_values[node]))\n",
    "    elif isMax == \"min\":\n",
    "        for node in _s_values:\n",
    "            final_s_values.append(min(_s_values[node]))\n",
    "    return final_s_values\n",
    "\n",
    "\n",
    "def intersection(lst1, lst2):\n",
    "    \"\"\"Helper Function to find intersecting terms from the two input lists of (term, s_Value)\"\"\"\n",
    "    da = {v: k for v, k in lst1}\n",
    "    db = {v: k for v, k in lst2}\n",
    "    return [(da[k], db[k]) for k in da.keys() & db.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downward Graph\n",
    "def common_children_go_ids(goids, godag):\n",
    "    \"\"\"\n",
    "    This function finds the common children in the GO\n",
    "    tree of the list of goids in the input.\n",
    "    \"\"\"\n",
    "    # Find candidates from first\n",
    "    rec = godag[goids[0]]\n",
    "    candidates = rec.get_all_lower()\n",
    "    candidates.update({goids[0]})\n",
    "    # Find intersection with second to nth goid\n",
    "    for goid in goids[1:]:\n",
    "        rec = godag[goid]\n",
    "        children = rec.get_all_lower()\n",
    "        children.update({goid})\n",
    "        # Find the intersection with the candidates, and update.\n",
    "        candidates.intersection_update(children)\n",
    "    return candidates\n",
    "\n",
    "\n",
    "def highest_common_descendant(goterms, godag):\n",
    "    \"\"\"\n",
    "    This function gets the nearest common descendant\n",
    "    using the above function.\n",
    "    Only returns single most specific - assumes unique exists.\n",
    "    \"\"\"\n",
    "    # Take the element at minimum depth.\n",
    "    common_children = common_children_go_ids(goterms, godag)\n",
    "    if len(common_children) != 0:\n",
    "        # take reldepth attribute instead of depth to accomodate all relationships\n",
    "        return min(common_children, key=lambda t: godag[t].reldepth)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def all_paths_to_bottom(term, godag, x):\n",
    "    # inputs: term_id and Go dag with 'relationship' as optional attributes\n",
    "    \"\"\"Returns all possible paths to the root node\"\"\"\n",
    "    if term not in godag:\n",
    "        sys.stderr.write(\"Term %s not found!\\n\" % term)\n",
    "        return\n",
    "\n",
    "    def _all_paths_to_bottom_recursive(rec):\n",
    "\n",
    "        if rec.reldepth == godag[term].reldepth + x:\n",
    "            return [[rec]]\n",
    "        else:\n",
    "            paths = []\n",
    "            children = rec.get_goterms_lower()\n",
    "            for child in children:\n",
    "                bottom_paths = _all_paths_to_bottom_recursive(child)\n",
    "                for bottom_path in bottom_paths:\n",
    "                    bottom_path.append(rec)\n",
    "                    paths.append(bottom_path)\n",
    "            return paths\n",
    "\n",
    "    go_term = godag[term]\n",
    "    return _all_paths_to_bottom_recursive(go_term)\n",
    "\n",
    "\n",
    "def Downward_Semantic_Value(go_id, go, x):\n",
    "    \"\"\"input: goterm_id\n",
    "    returns all of the weighted nodes in path to the Goterm from the children at the xth level below\n",
    "    #relationship types are global variables with appropriate weights\n",
    "    \"\"\"\n",
    "    all_all_paths = all_paths_to_bottom(go_id, go, x)\n",
    "    # print(len(all_all_paths))\n",
    "    S_values = list()\n",
    "    for index, path in enumerate(all_all_paths):\n",
    "        S_values.append([])\n",
    "        # print(\"index = \" + str(index))\n",
    "        path.reverse()\n",
    "        for idx, term in enumerate(path):\n",
    "            # print (term.item_id)\n",
    "            if idx == 0:  # which is on idx = 0\n",
    "                S_values[index].append((go_id, 1))\n",
    "            if idx < len(path) - 1:\n",
    "                if term.relationship != {}:\n",
    "                    # print(term.relationship.keys())\n",
    "                    if \"part_of\" in term.relationship:\n",
    "                        if path[idx + 1] in term.relationship[\"part_of\"]:\n",
    "                            S_values[index].append(\n",
    "                                (\n",
    "                                    path[idx + 1].item_id,\n",
    "                                    S_values[index][idx][1] * part_of,\n",
    "                                )\n",
    "                            )\n",
    "                        else:\n",
    "                            S_values[index].append(\n",
    "                                (path[idx + 1].item_id, S_values[index][idx][1] * is_a)\n",
    "                            )\n",
    "                    elif \"regulates\" in term.relationship:\n",
    "                        if path[idx + 1] in term.relationship[\"regulates\"]:\n",
    "                            S_values[index].append(\n",
    "                                (\n",
    "                                    path[idx + 1].item_id,\n",
    "                                    S_values[index][idx][1] * regulates,\n",
    "                                )\n",
    "                            )\n",
    "                        else:\n",
    "                            S_values[index].append(\n",
    "                                (path[idx + 1].item_id, S_values[index][idx][1] * is_a)\n",
    "                            )\n",
    "                    elif \"negatively_regulates\" in term.relationship:\n",
    "                        if path[idx + 1] in term.relationship[\"negatively_regulates\"]:\n",
    "                            S_values[index].append(\n",
    "                                (\n",
    "                                    path[idx + 1].item_id,\n",
    "                                    S_values[index][idx][1] * negatively_regulates,\n",
    "                                )\n",
    "                            )\n",
    "                        else:\n",
    "                            S_values[index].append(\n",
    "                                (path[idx + 1].item_id, S_values[index][idx][1] * is_a)\n",
    "                            )\n",
    "                    elif \"positively_regulates\" in term.relationship:\n",
    "                        if path[idx + 1] in term.relationship[\"positively_regulates\"]:\n",
    "                            S_values[index].append(\n",
    "                                (\n",
    "                                    path[idx + 1].item_id,\n",
    "                                    S_values[index][idx][1] * positively_regulates,\n",
    "                                )\n",
    "                            )\n",
    "                        else:\n",
    "                            S_values[index].append(\n",
    "                                (path[idx + 1].item_id, S_values[index][idx][1] * is_a)\n",
    "                            )\n",
    "                else:\n",
    "                    S_values[index].append(\n",
    "                        (path[idx + 1].item_id, S_values[index][idx][1] * is_a)\n",
    "                    )\n",
    "    return final_values(S_values, \"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating Similarity\n",
    "def Similarity_of_Two_GOTerms(go_id1, go_id2, go, method):\n",
    "    if method == \"Baseline_LCA\":\n",
    "        lca = lowest_common_ancestor((go_id1, go_id2), go)\n",
    "        # print(lca)\n",
    "        sim_lca = Semantic_Value(lca, go, method)\n",
    "        sim1 = Semantic_Value(go_id1, go, method)\n",
    "        sim2 = Semantic_Value(go_id2, go, method)\n",
    "        # sim1[1] and sim2[1] are the sums of all the nodes on the path with the max s-values.\n",
    "        sum_sim1_sim2 = sim1[1] + sim2[1]\n",
    "        return (sim_lca[1] * 2) / sum_sim1_sim2\n",
    "\n",
    "    elif method == \"GOntoSim\":\n",
    "        hcd = highest_common_descendant((go_id1, go_id2), go)\n",
    "        if hcd != 0:\n",
    "            hcd_depth = go[hcd].reldepth\n",
    "            go1_depth = go[go_id1].reldepth\n",
    "            go2_depth = go[go_id2].reldepth\n",
    "            x = hcd_depth - go1_depth\n",
    "            y = hcd_depth - go2_depth\n",
    "            sv_a = Downward_Semantic_Value(go_id1, go, x)\n",
    "            sv_b = Downward_Semantic_Value(go_id2, go, y)\n",
    "            intersecting_terms = intersection(sv_a, sv_b)\n",
    "            numerator = sum(\n",
    "                [x for t in intersecting_terms for x in t]\n",
    "            )  # Sum of common terms in all paths wrt to each of the 2 terms\n",
    "            denominator = sum(x for y, x in sv_a) + sum(\n",
    "                x for y, x in sv_b\n",
    "            )  # (where sv_a has 2 values for each term, second being the SV)\n",
    "            sim_down = numerator / denominator\n",
    "        else:\n",
    "            sim_down = 0\n",
    "        sim_upper = Similarity_of_Two_GOTerms(go_id1, go_id2, go, \"Baseline_LCA\")\n",
    "        sim = (sim_down * 0.5) + (sim_upper * 0.5)\n",
    "        # sim = (sim_down*0.3) + (sim_upper*0.7)\n",
    "        return sim\n",
    "\n",
    "    elif method == \"wang\" or method == \"Baseline\" or method == \"GOGO\":\n",
    "        sv_a = Semantic_Value(go_id1, go, method)\n",
    "        sv_b = Semantic_Value(go_id2, go, method)\n",
    "        intersecting_terms = intersection(sv_a, sv_b)\n",
    "        numerator = sum([x for t in intersecting_terms for x in t])\n",
    "        denominator = sum(x for y, x in sv_a) + sum(\n",
    "            x for y, x in sv_b\n",
    "        )  # (where sv_a has 2 values for each term, second being the SV)\n",
    "        Similarity = numerator / denominator\n",
    "        return Similarity\n",
    "    elif method == \"Baseline_Desc\":\n",
    "        hcd = highest_common_descendant((go_id1, go_id2), go)\n",
    "        if hcd != 0:\n",
    "            hcd_depth = go[hcd].reldepth\n",
    "            go1_depth = go[go_id1].reldepth\n",
    "            go2_depth = go[go_id2].reldepth\n",
    "            x = hcd_depth - go1_depth\n",
    "            y = hcd_depth - go2_depth\n",
    "            sv_a = Downward_Semantic_Value(go_id1, go, x)\n",
    "            sv_b = Downward_Semantic_Value(go_id2, go, y)\n",
    "            intersecting_terms = intersection(sv_a, sv_b)\n",
    "            numerator = sum(\n",
    "                [x for t in intersecting_terms for x in t]\n",
    "            )  # Sum of common terms in all paths wrt to each of the 2 terms\n",
    "            denominator = sum(x for y, x in sv_a) + sum(\n",
    "                x for y, x in sv_b\n",
    "            )  # (where sv_a has 2 values for each term, second being the SV)\n",
    "            sim_down = numerator / denominator\n",
    "        else:\n",
    "            sim_down = 0\n",
    "        sim_upper = Similarity_of_Two_GOTerms(go_id1, go_id2, go, \"Baseline\")\n",
    "        sim = (sim_down * 0.5) + (sim_upper * 0.5)\n",
    "        # sim = (sim_down*0.3) + (sim_upper*0.7)\n",
    "        return sim\n",
    "    elif method == \"Baseline_Desc_only\":\n",
    "        hcd = highest_common_descendant((go_id1, go_id2), go)\n",
    "        if hcd != 0:\n",
    "            hcd_depth = go[hcd].reldepth\n",
    "            go1_depth = go[go_id1].reldepth\n",
    "            go2_depth = go[go_id2].reldepth\n",
    "            x = hcd_depth - go1_depth\n",
    "            y = hcd_depth - go2_depth\n",
    "            sv_a = Downward_Semantic_Value(go_id1, go, x)\n",
    "            sv_b = Downward_Semantic_Value(go_id2, go, y)\n",
    "            intersecting_terms = intersection(sv_a, sv_b)\n",
    "            numerator = sum(\n",
    "                [x for t in intersecting_terms for x in t]\n",
    "            )  # Sum of common terms in all paths wrt to each of the 2 terms\n",
    "            denominator = sum(x for y, x in sv_a) + sum(\n",
    "                x for y, x in sv_b\n",
    "            )  # (where sv_a has 2 values for each term, second being the SV)\n",
    "            sim_down = numerator / denominator\n",
    "        else:\n",
    "            sim_down = 0\n",
    "        return sim_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Similarity_of_Set_of_GOTerms(set1, set2, method):\n",
    "    Sim1 = []\n",
    "    Sim2 = []\n",
    "    for idx, goterm in enumerate(set1):\n",
    "        # print (\"=========\", goterm)\n",
    "        Sim1.append([])\n",
    "        for goid in set2:\n",
    "            # print (goterm , goid)\n",
    "            Sim1[idx].append(\n",
    "                (goterm, goid, (Similarity_of_Two_GOTerms(goterm, goid, go, method)))\n",
    "            )\n",
    "    for idx, goterm in enumerate(set2):\n",
    "        Sim2.append([])\n",
    "        for goid in set1:\n",
    "            # print (goterm , goid)\n",
    "            Sim2[idx].append(\n",
    "                (goterm, goid, (Similarity_of_Two_GOTerms(goterm, goid, go, method)))\n",
    "            )\n",
    "    sem1 = []\n",
    "    sem2 = []\n",
    "\n",
    "    for index, goterm in enumerate(Sim1):\n",
    "        sem1.append((max(Sim1[index], key=lambda x: x[2])))\n",
    "    for index, goterm in enumerate(Sim2):\n",
    "        sem2.append((max(Sim2[index], key=lambda x: x[2])))\n",
    "\n",
    "    similarity = (sum(x[2] for x in sem1) + sum(x[2] for x in sem2)) / (\n",
    "        len(set1) + len(set2)\n",
    "    )\n",
    "\n",
    "    return round(similarity, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation: Clustering, AMI/ARI Scores\n",
    "\n",
    "\n",
    "def Similarity_Matrix(genes, method, S_values):\n",
    "    sim_matrix = []\n",
    "    for idx, gene in enumerate(genes):\n",
    "        print(gene)\n",
    "        sim_matrix.append(\n",
    "            [\n",
    "                (\n",
    "                    lambda x: Similarity_of_Set_of_GOTerms(\n",
    "                        x[1], gene[1], method, S_values\n",
    "                    )\n",
    "                )(x)\n",
    "                for x in genes\n",
    "            ]\n",
    "        )\n",
    "    return sim_matrix\n",
    "\n",
    "\n",
    "def Agglomerative_Clustering(pathway, Genes, n_clusters, method, S_values):\n",
    "    # Similarity Matrix\n",
    "    data = Similarity_Matrix(Genes, method, S_values)\n",
    "    length = len(data)\n",
    "    data1 = pd.DataFrame(\n",
    "        data=data, index=[x[0] for x in Genes], columns=[x[0] for x in Genes]\n",
    "    )\n",
    "    # print('similarity matrisx: ')\n",
    "    # print(data1)\n",
    "    # writeSim = pathway + \"_SimilarityMatrix.csv\"\n",
    "    # data1.to_csv(writeSim)\n",
    "    data_matrix = []\n",
    "    for row in data:\n",
    "        data_matrix.append([(lambda x: 1 - x)(x) for x in row])\n",
    "    my_data = pd.DataFrame(\n",
    "        data=data_matrix, index=[x[0] for x in Genes], columns=[x[0] for x in Genes]\n",
    "    )\n",
    "    return Agglomerative(my_data, Genes, pathway, n_clusters)\n",
    "\n",
    "\n",
    "def Agglomerative(data, Genes, pathway, n_clusters):\n",
    "    # model = AgglomerativeClustering(n_clusters, affinity='precomputed', linkage='complete').fit(data)\n",
    "    model = AgglomerativeClustering(\n",
    "        n_clusters, affinity=\"precomputed\", linkage=\"complete\"\n",
    "    ).fit_predict(data)\n",
    "    # Single linkage minimizes the distance between the closest observations of pairs of clusters.\n",
    "    GeneNames = [gene.GeneName for gene in Genes]\n",
    "    return model.tolist()\n",
    "\n",
    "\n",
    "def ARI_Score(label_pred, labels_true):\n",
    "    return adjusted_rand_score(label_pred, labels_true)\n",
    "\n",
    "\n",
    "def AMI_Score(label_pred, labels_true):\n",
    "    return adjusted_mutual_info_score(\n",
    "        label_pred, labels_true, average_method=\"arithmetic\"\n",
    "    )\n",
    "\n",
    "\n",
    "def cont_matrix(y_true, y_pred):\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return contingency_matrix\n",
    "\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # print(contingency_matrix)\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_id1 = \"GO:0005634\"\n",
    "go_id2 = \"GO:0042579\"\n",
    "go_id3 = \"GO:0005777\"\n",
    "go_id4 = \"GO:0031903\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0005634 and GO:0042579 = 0.74392511582464\n",
      "GO:0005777 and GO:0031903 = 0.6888698543860534\n"
     ]
    }
   ],
   "source": [
    "method = \"wang\"\n",
    "print(go_id1, \"and\", go_id2, \"=\", Similarity_of_Two_GOTerms(go_id1, go_id2, go, method))\n",
    "print(go_id3, \"and\", go_id4, \"=\", Similarity_of_Two_GOTerms(go_id3, go_id4, go, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GOTerm' object has no attribute 'reldepth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGOntoSim\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m Similarity_of_Two_GOTerms(go_id1, go_id2, go, method)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mSimilarity_of_Two_GOTerms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgo_id3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgo_id4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(go_id1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand\u001b[39m\u001b[38;5;124m\"\u001b[39m, go_id2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m, Similarity_of_Two_GOTerms(go_id1, go_id2, go, method))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(go_id3, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand\u001b[39m\u001b[38;5;124m\"\u001b[39m, go_id4, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m, Similarity_of_Two_GOTerms(go_id3, go_id4, go, method))\n",
      "Cell \u001b[1;32mIn[7], line 14\u001b[0m, in \u001b[0;36mSimilarity_of_Two_GOTerms\u001b[1;34m(go_id1, go_id2, go, method)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (sim_lca[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m sum_sim1_sim2\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGOntoSim\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 14\u001b[0m     hcd \u001b[38;5;241m=\u001b[39m \u001b[43mhighest_common_descendant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgo_id1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgo_id2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hcd \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     16\u001b[0m         hcd_depth \u001b[38;5;241m=\u001b[39m go[hcd]\u001b[38;5;241m.\u001b[39mreldepth\n",
      "Cell \u001b[1;32mIn[6], line 31\u001b[0m, in \u001b[0;36mhighest_common_descendant\u001b[1;34m(goterms, godag)\u001b[0m\n\u001b[0;32m     28\u001b[0m common_children \u001b[38;5;241m=\u001b[39m common_children_go_ids(goterms, godag)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(common_children) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# take reldepth attribute instead of depth to accomodate all relationships\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcommon_children\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgodag\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreldepth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[6], line 31\u001b[0m, in \u001b[0;36mhighest_common_descendant.<locals>.<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m     28\u001b[0m common_children \u001b[38;5;241m=\u001b[39m common_children_go_ids(goterms, godag)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(common_children) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# take reldepth attribute instead of depth to accomodate all relationships\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(common_children, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mgodag\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreldepth\u001b[49m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GOTerm' object has no attribute 'reldepth'"
     ]
    }
   ],
   "source": [
    "method = \"GOntoSim\"\n",
    "Similarity_of_Two_GOTerms(go_id1, go_id2, go, method)\n",
    "Similarity_of_Two_GOTerms(go_id3, go_id4, go, method)\n",
    "print(go_id1, \"and\", go_id2, \"=\", Similarity_of_Two_GOTerms(go_id1, go_id2, go, method))\n",
    "print(go_id3, \"and\", go_id4, \"=\", Similarity_of_Two_GOTerms(go_id3, go_id4, go, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0005634 and GO:0042579 = 0.8088116501220664\n",
      "GO:0005777 and GO:0031903 = 0.7966598157740757\n"
     ]
    }
   ],
   "source": [
    "method = \"GOGO\"\n",
    "Similarity_of_Two_GOTerms(go_id1, go_id2, go, method)\n",
    "Similarity_of_Two_GOTerms(go_id3, go_id4, go, method)\n",
    "print(go_id1, \"and\", go_id2, \"=\", Similarity_of_Two_GOTerms(go_id1, go_id2, go, method))\n",
    "print(go_id3, \"and\", go_id4, \"=\", Similarity_of_Two_GOTerms(go_id3, go_id4, go, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0005634 and GO:0042579 = 0.7246229452635147\n",
      "GO:0005777 and GO:0031903 = 0.6725006629541236\n"
     ]
    }
   ],
   "source": [
    "method = \"Baseline\"\n",
    "Similarity_of_Two_GOTerms(go_id1, go_id2, go, method)\n",
    "Similarity_of_Two_GOTerms(go_id3, go_id4, go, method)\n",
    "print(go_id1, \"and\", go_id2, \"=\", Similarity_of_Two_GOTerms(go_id1, go_id2, go, method))\n",
    "print(go_id3, \"and\", go_id4, \"=\", Similarity_of_Two_GOTerms(go_id3, go_id4, go, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0005634 and GO:0042579 = 0.8690532265661799\n",
      "GO:0005777 and GO:0031903 = 0.9131545338441889\n"
     ]
    }
   ],
   "source": [
    "method = \"Baseline_LCA\"\n",
    "Similarity_of_Two_GOTerms(go_id1, go_id2, go, method)\n",
    "Similarity_of_Two_GOTerms(go_id3, go_id4, go, method)\n",
    "print(go_id1, \"and\", go_id2, \"=\", Similarity_of_Two_GOTerms(go_id1, go_id2, go, method))\n",
    "print(go_id3, \"and\", go_id4, \"=\", Similarity_of_Two_GOTerms(go_id3, go_id4, go, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GOTerm' object has no attribute 'reldepth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline_Desc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m Similarity_of_Two_GOTerms(go_id1, go_id2, go, method)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mSimilarity_of_Two_GOTerms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgo_id3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgo_id4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(go_id1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand\u001b[39m\u001b[38;5;124m\"\u001b[39m, go_id2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m, Similarity_of_Two_GOTerms(go_id1, go_id2, go, method))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(go_id3, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand\u001b[39m\u001b[38;5;124m\"\u001b[39m, go_id4, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m, Similarity_of_Two_GOTerms(go_id3, go_id4, go, method))\n",
      "Cell \u001b[1;32mIn[7], line 49\u001b[0m, in \u001b[0;36mSimilarity_of_Two_GOTerms\u001b[1;34m(go_id1, go_id2, go, method)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Similarity\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline_Desc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 49\u001b[0m     hcd \u001b[38;5;241m=\u001b[39m \u001b[43mhighest_common_descendant\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgo_id1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgo_id2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hcd \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     51\u001b[0m         hcd_depth \u001b[38;5;241m=\u001b[39m go[hcd]\u001b[38;5;241m.\u001b[39mreldepth\n",
      "Cell \u001b[1;32mIn[6], line 31\u001b[0m, in \u001b[0;36mhighest_common_descendant\u001b[1;34m(goterms, godag)\u001b[0m\n\u001b[0;32m     28\u001b[0m common_children \u001b[38;5;241m=\u001b[39m common_children_go_ids(goterms, godag)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(common_children) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# take reldepth attribute instead of depth to accomodate all relationships\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcommon_children\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgodag\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreldepth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[1;32mIn[6], line 31\u001b[0m, in \u001b[0;36mhighest_common_descendant.<locals>.<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m     28\u001b[0m common_children \u001b[38;5;241m=\u001b[39m common_children_go_ids(goterms, godag)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(common_children) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# take reldepth attribute instead of depth to accomodate all relationships\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(common_children, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mgodag\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreldepth\u001b[49m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GOTerm' object has no attribute 'reldepth'"
     ]
    }
   ],
   "source": [
    "method = \"Baseline_Desc\"\n",
    "Similarity_of_Two_GOTerms(go_id1, go_id2, go, method)\n",
    "Similarity_of_Two_GOTerms(go_id3, go_id4, go, method)\n",
    "print(go_id1, \"and\", go_id2, \"=\", Similarity_of_Two_GOTerms(go_id1, go_id2, go, method))\n",
    "print(go_id3, \"and\", go_id4, \"=\", Similarity_of_Two_GOTerms(go_id3, go_id4, go, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
