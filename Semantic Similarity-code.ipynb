{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import Libraries\n",
    "\n",
    "from goatools.semantic import common_parent_go_ids, min_branch_length, semantic_distance, semantic_similarity\n",
    "from goatools.obo_parser import GODag\n",
    "from goatools.base import get_godag\n",
    "from goatools.semantic import resnik_sim\n",
    "from goatools.semantic import lin_sim\n",
    "from goatools.semantic import TermCounts, get_info_content\n",
    "from goatools.associations import read_associations\n",
    "from goatools.semantic import deepest_common_ancestor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn import metrics\n",
    "from scipy.cluster.hierarchy import dendrogram \n",
    "import scipy.cluster.hierarchy as shc\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "import sys\n",
    "import random\n",
    "\n",
    "# import annotations\n",
    "from ALL_EC_GOTERMS_IEA_MF import *\n",
    "from ALL_EC_GOTERMS_NonIEA_MF import *\n",
    "from ALL_EC_GOTERMS_IEA_BP import *\n",
    "from ALL_EC_GOTERMS_NonIEA_BP import *\n",
    "\n",
    "# define named tuple\n",
    "Gene = namedtuple('Gene', 'GeneName GOAnnotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EXISTS: go-basic.obo\n",
      "go-basic.obo: fmt(1.2) rel(2020-01-01) 47,337 GO Terms; optional_attrs(relationship)\n"
     ]
    }
   ],
   "source": [
    "# load Gene Ontology\n",
    "go = get_godag(\"go-basic.obo\", optional_attrs={'relationship'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Relationship Semantic Contribution \n",
    "is_a = 0.8\n",
    "part_of = 0.6\n",
    "regulates = 0.7\n",
    "negatively_regulates = 0.7\n",
    "positively_regulates = 0.7\n",
    "reg = 'reg0.7'\n",
    "c = 0.67    #for GOGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions\n",
    "def all_common_parent_go_ids(goids, godag):\n",
    "\t'''\n",
    "\t\tThis function finds the common ancestors in the GO\n",
    "\t\ttree of the list of goids in the input.\n",
    "\t'''\n",
    "\t# Find candidates from first\n",
    "\trec = godag[goids[0]]\n",
    "\tcandidates = rec.get_all_upper()\n",
    "\tcandidates.update({goids[0]})\n",
    "\n",
    "\t# Find intersection with second to nth goid\n",
    "\tfor goid in goids[1:]:\n",
    "\t\trec = godag[goid]\n",
    "\t\tparents = rec.get_all_upper()\n",
    "\t\tparents.update({goid})\n",
    "\n",
    "\t\t# Find the intersection with the candidates, and update.\n",
    "\t\tcandidates.intersection_update(parents)\n",
    "\treturn candidates\n",
    "def lowest_common_ancestor(goterms, godag):\n",
    "\t'''\n",
    "\t\tThis function gets the nearest common ancestor\n",
    "\t\tusing the above function.\n",
    "\t\tOnly returns single most specific - assumes unique exists.\n",
    "\t'''\n",
    "\t# Take the element at maximum depth.\n",
    "\treturn max(all_common_parent_go_ids(goterms, godag), key=lambda t: godag[t].depth)\n",
    "def all_paths_to_top(term, godag):\n",
    "\t# inputs: term_id and Go dag with 'relationship' as optional attributes\n",
    "\t\t\"\"\" Returns all possible paths to the root node\"\"\"\n",
    "\t\tif term not in godag:\n",
    "\t\t\tsys.stderr.write(\"Term %s not found!\\n\" % term)\n",
    "\t\t\treturn\n",
    "\t\tdef _all_paths_to_top_recursive(rec):\n",
    "\t\t\tif rec.level == 0:\n",
    "\t\t\t\treturn [[rec]]\n",
    "\t\t\tpaths = []\n",
    "\t\t\tparents = rec.get_goterms_upper()\n",
    "\t\t\tfor parent in parents:\n",
    "\t\t\t\ttop_paths = _all_paths_to_top_recursive(parent)\n",
    "\t\t\t\tfor top_path in top_paths:\n",
    "\t\t\t\t\ttop_path.append(rec)\n",
    "\t\t\t\t\tpaths.append(top_path)\n",
    "\t\t\treturn paths\n",
    "\n",
    "\t\tgo_term = godag[term]\n",
    "\t\treturn _all_paths_to_top_recursive(go_term)\n",
    "    \n",
    "    \n",
    "def all_paths_to_top_wang(term, godag, optional_relationships):\n",
    "\t# inputs: term_id and Go dag with 'relationship' as optional attributes\n",
    "\t\t\"\"\" Returns all possible paths to the root node\"\"\"\n",
    "\t\tif term not in godag:\n",
    "\t\t\tsys.stderr.write(\"Term %s not found!\\n\" % term)\n",
    "\t\t\treturn\n",
    "\t\tdef _all_paths_to_top_recursive(rec):\n",
    "\t\t\tif rec.level == 0:\n",
    "\t\t\t\treturn [[rec]]\n",
    "\t\t\tpaths = []\n",
    "\t\t\tparents = rec.get_goterms_upper_rels(optional_relationships)\n",
    "\t\t\t#parents = rec.get_goterms_upper()\n",
    "\t\t\tfor parent in parents:\n",
    "\t\t\t\t#parent = go[parent1]\n",
    "\t\t\t\ttop_paths = _all_paths_to_top_recursive(parent)\n",
    "\t\t\t\tfor top_path in top_paths:\n",
    "\t\t\t\t\ttop_path.append(rec)\n",
    "\t\t\t\t\tpaths.append(top_path)\n",
    "\t\t\treturn paths\n",
    "\t\tgo_term = godag[term]\n",
    "\t\treturn _all_paths_to_top_recursive(go_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Semantic_Value(go_id, go, method):\n",
    "\t''' input: goterm_id \n",
    "\t\treturns all of the weighted (all relatinships in go-basic) paths to root \n",
    "\t\t#relationship types are global variables with appropriate weights\n",
    "\t'''\n",
    "\tif method == 'wang':\n",
    "\t\t# calculates all paths to top (with all relationships)\n",
    "\t\toptional_relationships = {'part_of'}\n",
    "\t\tall_all_paths = all_paths_to_top_wang(go_id, go, optional_relationships)\n",
    "\t\tS_values = list()\n",
    "\t\tfor index, path in enumerate(all_all_paths):\n",
    "\t\t\tS_values.append([])\n",
    "\t\t\t#print(\"index = \" + str(index))\n",
    "\t\t\tpath.reverse()\n",
    "\t\t\tfor idx, term in enumerate(path):\n",
    "\t\t\t\t# Semantic Value of the term itself is always 1 \n",
    "\t\t\t\tif idx == 0:\t#which is on idx = 0 \n",
    "\t\t\t\t\tS_values[index].append((go_id, 1))\n",
    "\t\t\t\tif idx < len(path)-1:\n",
    "\t\t\t\t\tif term.relationship != {}:\n",
    "\t\t\t\t\t\t#print(term.relationship.keys())\n",
    "\t\t\t\t\t\tif 'part_of' in term.relationship:\n",
    "\t\t\t\t\t\t\tif path[idx+1] in term.relationship['part_of']:\n",
    "\t\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id, S_values[index][idx][1] * part_of))\n",
    "\t\t\t\t\t\t\telse: \n",
    "\t\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id,S_values[index][idx][1] * is_a))\n",
    "\t\t\t\t\t\telse: \n",
    "\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id, S_values[index][idx][1] * is_a))\n",
    "\t\t\t\t\telse: \n",
    "\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id,S_values[index][idx][1] * is_a))\n",
    "\t\treturn final_values(S_values,'max')\n",
    "\telif method == 'GOGO':\n",
    "\t\toptional_relationships = {'part_of'}\n",
    "\t\tall_all_paths = all_paths_to_top_wang(go_id, go, optional_relationships)\n",
    "\t\tS_values = list()\n",
    "\t\tfor index, path in enumerate(all_all_paths):\n",
    "\t\t\tS_values.append([])\n",
    "\t\t\t#print(\"index = \" + str(index))\n",
    "\t\t\tpath.reverse()\n",
    "\t\t\tfor idx, term in enumerate(path):\n",
    "\t\t\t\t# Semantic Value of the term itself is always 1 \n",
    "\t\t\t\tif idx == 0:\t#which is on idx = 0 \n",
    "\t\t\t\t\tS_values[index].append((go_id, 1))\n",
    "\t\t\t\tif idx < len(path)-1:\n",
    "\t\t\t\t\tif term.relationship != {}:\n",
    "\t\t\t\t\t\t#print(term.relationship.keys())\n",
    "\t\t\t\t\t\tif 'part_of' in term.relationship:\n",
    "\t\t\t\t\t\t\tif path[idx+1] in term.relationship['part_of']:\n",
    "\t\t\t\t\t\t\t\tweight = (1 / (c + len(go[path[idx+1].item_id].children))) + part_of\n",
    "\t\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id, S_values[index][idx][1] * weight))\n",
    "\t\t\t\t\t\t\telse: \n",
    "\t\t\t\t\t\t\t\tweight = (1 / (c + len(go[path[idx+1].item_id].children))) + is_a\n",
    "\t\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id, S_values[index][idx][1] * weight ))\n",
    "\t\t\t\t\t\telse: \n",
    "\t\t\t\t\t\t\tweight = (1 / (c + len(go[path[idx+1].item_id].children))) + is_a\n",
    "\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id, S_values[index][idx][1] * weight ))\n",
    "\t\t\t\t\telse: \n",
    "\t\t\t\t\t\tweight = (1 / (c + len(go[path[idx+1].item_id].children))) + is_a\n",
    "\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id, S_values[index][idx][1] * weight ))\n",
    "\t\treturn final_values(S_values,'max')\n",
    "\t#Baseline Measure - Almost Same as Semantic Value; only Difference is the weight of root as ancestor = 0 and different realtionships\n",
    "\telse:\n",
    "\t\tall_all_paths = all_paths_to_top(go_id, go)\n",
    "\t\tS_values = list()\n",
    "\t\t#print(go_id)\n",
    "\t\tfor index, path in enumerate(all_all_paths):\n",
    "\t\t\tS_values.append([])\n",
    "\t\t\t#print(\"index = \" + str(index))\n",
    "\t\t\tpath.reverse()\n",
    "\t\t\tfor idx, term in enumerate(path):\n",
    "\t\t\t\t# Semantic Value of the term itself is always 1 \n",
    "\t\t\t\tif idx == 0:\t#which is on idx = 0 \n",
    "\t\t\t\t\tS_values[index].append((go_id, 1))\n",
    "\t\t\t\tif idx < len(path)-1 and path[idx+1].item_id != 'GO:0003674' and path[idx+1].item_id != 'GO:0005575' and path[idx+1].item_id != 'GO:0008150':\n",
    "\t\t\t\t\tif term.relationship != {}: \n",
    "\t\t\t\t\t\t#print(term.relationship.keys())\n",
    "\t\t\t\t\t\tif 'part_of' in term.relationship:\n",
    "\t\t\t\t\t\t\tif path[idx+1] in term.relationship['part_of']:\n",
    "\t\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id, S_values[index][idx][1] * part_of))\n",
    "\t\t\t\t\t\t\telse: \n",
    "\t\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id,S_values[index][idx][1] * is_a))\n",
    "\t\t\t\t\t\telif 'regulates' in term.relationship:\n",
    "\t\t\t\t\t\t\tif path[idx+1] in term.relationship['regulates']:\n",
    "\t\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id, S_values[index][idx][1] * regulates))\n",
    "\t\t\t\t\t\t\telse: \n",
    "\t\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id,S_values[index][idx][1] * is_a))\n",
    "\t\t\t\t\t\telif 'negatively_regulates' in term.relationship:\n",
    "\t\t\t\t\t\t\tif path[idx+1] in term.relationship['negatively_regulates']:\n",
    "\t\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id,S_values[index][idx][1] * negatively_regulates))\n",
    "\t\t\t\t\t\t\telse: \n",
    "\t\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id,S_values[index][idx][1] * is_a))\n",
    "\t\t\t\t\t\telif 'positively_regulates' in term.relationship:\n",
    "\t\t\t\t\t\t\tif path[idx+1] in term.relationship['positively_regulates']:\n",
    "\t\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id,S_values[index][idx][1] * positively_regulates))\n",
    "\t\t\t\t\t\t\telse: \n",
    "\t\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id, S_values[index][idx][1] * is_a))\n",
    "\t\t\t\t\t\telse: \n",
    "\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id,S_values[index][idx][1] * is_a))\n",
    "\t\t\t\t\telse: \n",
    "\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id,S_values[index][idx][1] * is_a))\n",
    "\t\t\t\tif (term.item_id == 'GO:0003674' or term.item_id == 'GO:0005575' or term.item_id == 'GO:0008150'):\n",
    "\t\t\t\t\t\tS_values[index].append((term.item_id, 0))\n",
    "\t\tif method == 'Baseline':\n",
    "\t\t\treturn final_values(S_values, 'max')\n",
    "\t\tif method == 'Baseline_LCA' :\n",
    "\t\t\tsvaluesfinal = final_values(S_values, 'max')\n",
    "\t\t\t# Replace the max or min s-values in all paths to assign only one value to each node, consistent in all paths\n",
    "\t\t\tS_values_Modified = list()\n",
    "\t\t\tfor index, path in enumerate(S_values):\n",
    "\t\t\t\tS_values_Modified.append([])\n",
    "\t\t\t\tfor idx, term1 in enumerate(path):\n",
    "\t\t\t#\t\tprint(list(value for (term, value) in svaluesfinal if term == term1[0]))\n",
    "\t\t\t\t\tind = [value for (term, value) in svaluesfinal if term == term1[0]]\n",
    "\t\t\t\t\tS_values_Modified[index].append((path[idx][0],ind[0]))\n",
    "\t\t\tSumOfNodesOnEachPath = list()\n",
    "\t\t\tfor index, path in enumerate(S_values_Modified):\n",
    "\t\t\t#\tprint(\"Modified index and path: \", index, path)\n",
    "\t\t\t\tSumOfNodesOnEachPath.append(sum(x[1] for x in path))\n",
    "\t\t\tmaxPath = SumOfNodesOnEachPath.index(max(SumOfNodesOnEachPath))\n",
    "\t\t\treturn S_values_Modified[maxPath], SumOfNodesOnEachPath[maxPath]\n",
    "\n",
    "def final_values(S_values, isMax):\n",
    "\t''' helper function to assign the max of the weights assigned to each term'''\n",
    "\t#S_values = sorted(S_values, key=lambda x: x[0])\n",
    "\tunique_terms_s_values = []\n",
    "\tfor path in S_values:\n",
    "\t\tfor term in path:\n",
    "\t\t\tunique_terms_s_values.append(term)\n",
    "\tunique_terms_s_values = sorted(unique_terms_s_values, key=lambda x: x[0])\n",
    "\t_s_values = {}\n",
    "\tfor y, x in unique_terms_s_values: \n",
    "\t\tif y in _s_values: \n",
    "\t\t\t_s_values[y].append((y,x)) \n",
    "\t\telse: \n",
    "\t\t\t_s_values[y] = [(y, x)]\n",
    "\tfinal_s_values = []\n",
    "\tif(isMax == 'max'):\n",
    "\t\tfor node in _s_values:\n",
    "\t\t\tfinal_s_values.append(max(_s_values[node]))\n",
    "\telif (isMax == 'min'):\n",
    "\t\tfor node in _s_values:\n",
    "\t\t\tfinal_s_values.append(min(_s_values[node]))\n",
    "\treturn final_s_values\n",
    "def intersection(lst1, lst2): \n",
    "\t'''Helper Function to find intersecting terms from the two input lists of (term, s_Value)'''\n",
    "\tda = {v:k for v, k in lst1}\n",
    "\tdb = {v:k for v, k in lst2} \n",
    "\treturn [(da[k],db[k]) for k in da.keys() & db.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downward Graph \t\t\t\t  \n",
    "def common_children_go_ids(goids, godag):\n",
    "\t'''\n",
    "\t\tThis function finds the common children in the GO\n",
    "\t\ttree of the list of goids in the input.\n",
    "\t'''\n",
    "\t# Find candidates from first\n",
    "\trec = godag[goids[0]]\n",
    "\tcandidates = rec.get_all_lower()\n",
    "\tcandidates.update({goids[0]})\n",
    "\t# Find intersection with second to nth goid\n",
    "\tfor goid in goids[1:]:\n",
    "\t\trec = godag[goid]\n",
    "\t\tchildren = rec.get_all_lower()\n",
    "\t\tchildren.update({goid})\n",
    "\t\t# Find the intersection with the candidates, and update.\n",
    "\t\tcandidates.intersection_update(children)\n",
    "\treturn candidates\n",
    "def highest_common_descendant(goterms, godag):\n",
    "\t'''\n",
    "\t\tThis function gets the nearest common descendant\n",
    "\t\tusing the above function.\n",
    "\t\tOnly returns single most specific - assumes unique exists.\n",
    "\t'''\n",
    "\t# Take the element at minimum depth.\n",
    "\tcommon_children = common_children_go_ids(goterms, godag)\n",
    "\tif len(common_children) != 0:\n",
    "\t\t# take reldepth attribute instead of depth to accomodate all relationships\n",
    "\t\treturn min(common_children, key=lambda t: godag[t].reldepth)\n",
    "\telse:\n",
    "\t\treturn 0\n",
    "def all_paths_to_bottom(term, godag, x):\n",
    "\t\t# inputs: term_id and Go dag with 'relationship' as optional attributes\n",
    "\t\"\"\" Returns all possible paths to the root node\"\"\"\n",
    "\tif term not in godag:\n",
    "\t\tsys.stderr.write(\"Term %s not found!\\n\" % term)\n",
    "\t\treturn\n",
    "\n",
    "\tdef _all_paths_to_bottom_recursive(rec):\n",
    "\n",
    "\t\tif rec.reldepth == godag[term].reldepth+x:\n",
    "\t\t\treturn [[rec]]\n",
    "\t\telse:\n",
    "\t\t\tpaths = []\n",
    "\t\t\tchildren = rec.get_goterms_lower()\n",
    "\t\t\tfor child in children:\n",
    "\t\t\t\tbottom_paths = _all_paths_to_bottom_recursive(child)\n",
    "\t\t\t\tfor bottom_path in bottom_paths:\n",
    "\t\t\t\t\tbottom_path.append(rec)\n",
    "\t\t\t\t\tpaths.append(bottom_path)\n",
    "\t\t\treturn paths\n",
    "\tgo_term = godag[term]\n",
    "\treturn _all_paths_to_bottom_recursive(go_term)\n",
    "def Downward_Semantic_Value(go_id, go, x):\n",
    "\t''' input: goterm_id \n",
    "\t\treturns all of the weighted nodes in path to the Goterm from the children at the xth level below\n",
    "\t\t#relationship types are global variables with appropriate weights\n",
    "\t'''\n",
    "\tall_all_paths = all_paths_to_bottom(go_id, go, x)\n",
    "\t#print(len(all_all_paths))\n",
    "\tS_values = list()\n",
    "\tfor index, path in enumerate(all_all_paths):\n",
    "\t\tS_values.append([])\n",
    "\t\t#print(\"index = \" + str(index))\n",
    "\t\tpath.reverse()\n",
    "\t\tfor idx, term in enumerate(path):\n",
    "\t\t\t#print (term.item_id)\n",
    "\t\t\tif idx == 0:\t#which is on idx = 0 \n",
    "\t\t\t\tS_values[index].append((go_id, 1))\n",
    "\t\t\tif idx < len(path)-1:\n",
    "\t\t\t\tif term.relationship != {}: \n",
    "\t\t\t\t\t#print(term.relationship.keys())\n",
    "\t\t\t\t\tif 'part_of' in term.relationship:\n",
    "\t\t\t\t\t\tif path[idx+1] in term.relationship['part_of']:\n",
    "\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id, S_values[index][idx][1] * part_of))\n",
    "\t\t\t\t\t\telse: \n",
    "\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id,S_values[index][idx][1] * is_a))\n",
    "\t\t\t\t\telif 'regulates' in term.relationship:\n",
    "\t\t\t\t\t\tif path[idx+1] in term.relationship['regulates']:\n",
    "\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id, S_values[index][idx][1] * regulates))\n",
    "\t\t\t\t\t\telse: \n",
    "\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id,S_values[index][idx][1] * is_a))\n",
    "\t\t\t\t\telif 'negatively_regulates' in term.relationship:\n",
    "\t\t\t\t\t\tif path[idx+1] in term.relationship['negatively_regulates']:\n",
    "\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id,S_values[index][idx][1] * negatively_regulates))\n",
    "\t\t\t\t\t\telse: \n",
    "\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id,S_values[index][idx][1] * is_a))\n",
    "\t\t\t\t\telif 'positively_regulates' in term.relationship:\n",
    "\t\t\t\t\t\tif path[idx+1] in term.relationship['positively_regulates']:\n",
    "\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id,S_values[index][idx][1] * positively_regulates))\n",
    "\t\t\t\t\t\telse: \n",
    "\t\t\t\t\t\t\tS_values[index].append((path[idx+1].item_id, S_values[index][idx][1] * is_a))\n",
    "\t\t\t\telse: \n",
    "\t\t\t\t\tS_values[index].append((path[idx+1].item_id,S_values[index][idx][1] * is_a))\n",
    "\treturn final_values(S_values, 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating Similarity \n",
    "def Similarity_of_Two_GOTerms(go_id1, go_id2, go, method):\n",
    "\tif method == 'Baseline_LCA':\n",
    "\t\tlca = lowest_common_ancestor((go_id1, go_id2), go)\n",
    "\t\t#print(lca)\n",
    "\t\tsim_lca = Semantic_Value(lca, go, method)\n",
    "\t\tsim1 = Semantic_Value(go_id1, go, method)\n",
    "\t\tsim2 = Semantic_Value(go_id2, go, method)\n",
    "\t\t# sim1[1] and sim2[1] are the sums of all the nodes on the path with the max s-values. \n",
    "\t\tsum_sim1_sim2 = (sim1[1] + sim2[1])\n",
    "\t\treturn ((sim_lca[1]*2)/sum_sim1_sim2)\n",
    "\t\n",
    "\telif method == 'GOntoSim':\n",
    "\t\thcd = highest_common_descendant((go_id1, go_id2), go)\n",
    "\t\tif hcd != 0:\n",
    "\t\t\thcd_depth = go[hcd].reldepth\n",
    "\t\t\tgo1_depth = go[go_id1].reldepth\n",
    "\t\t\tgo2_depth = go[go_id2].reldepth\n",
    "\t\t\tx = hcd_depth - go1_depth\n",
    "\t\t\ty = hcd_depth - go2_depth\n",
    "\t\t\tsv_a = Downward_Semantic_Value(go_id1, go, x)\n",
    "\t\t\tsv_b = Downward_Semantic_Value(go_id2, go, y)\n",
    "\t\t\tintersecting_terms = intersection(sv_a,sv_b)\n",
    "\t\t\tnumerator = sum([x for t in intersecting_terms for x in t]) # Sum of common terms in all paths wrt to each of the 2 terms\n",
    "\t\t\tdenominator = sum(x for y, x in sv_a) + sum(x for y, x in sv_b) #(where sv_a has 2 values for each term, second being the SV)\n",
    "\t\t\tsim_down = (numerator/denominator)\n",
    "\t\telse:\n",
    "\t\t\tsim_down = 0\n",
    "\t\tsim_upper = Similarity_of_Two_GOTerms(go_id1,go_id2, go, 'Baseline_LCA')\n",
    "\t\tsim = (sim_down*0.5) + (sim_upper*0.5)\n",
    "\t\t#sim = (sim_down*0.3) + (sim_upper*0.7)\n",
    "\t\treturn sim\n",
    "\t\t\n",
    "\telif method == 'wang' or method == 'Baseline' or method == 'GOGO':\n",
    "\t\tsv_a = Semantic_Value(go_id1, go, method)\n",
    "\t\tsv_b = Semantic_Value(go_id2, go,  method)\n",
    "\t\tintersecting_terms = intersection(sv_a,sv_b)\n",
    "\t\tnumerator = sum([x for t in intersecting_terms for x in t])\n",
    "\t\tdenominator = sum(x for y, x in sv_a) + sum(x for y, x in sv_b) #(where sv_a has 2 values for each term, second being the SV)\n",
    "\t\tSimilarity = (numerator/denominator)\n",
    "\t\treturn Similarity\n",
    "\telif method == 'Baseline_Desc':\n",
    "\t\thcd = highest_common_descendant((go_id1, go_id2), go)\n",
    "\t\tif hcd != 0:\n",
    "\t\t\thcd_depth = go[hcd].reldepth\n",
    "\t\t\tgo1_depth = go[go_id1].reldepth\n",
    "\t\t\tgo2_depth = go[go_id2].reldepth\n",
    "\t\t\tx = hcd_depth - go1_depth\n",
    "\t\t\ty = hcd_depth - go2_depth\n",
    "\t\t\tsv_a = Downward_Semantic_Value(go_id1, go, x)\n",
    "\t\t\tsv_b = Downward_Semantic_Value(go_id2, go, y)\n",
    "\t\t\tintersecting_terms = intersection(sv_a,sv_b)\n",
    "\t\t\tnumerator = sum([x for t in intersecting_terms for x in t]) # Sum of common terms in all paths wrt to each of the 2 terms\n",
    "\t\t\tdenominator = sum(x for y, x in sv_a) + sum(x for y, x in sv_b) #(where sv_a has 2 values for each term, second being the SV)\n",
    "\t\t\tsim_down = (numerator/denominator)\n",
    "\t\telse:\n",
    "\t\t\tsim_down = 0\n",
    "\t\tsim_upper = Similarity_of_Two_GOTerms(go_id1,go_id2, go, 'Baseline')\n",
    "\t\tsim = (sim_down*0.5) + (sim_upper*0.5)\n",
    "\t\t#sim = (sim_down*0.3) + (sim_upper*0.7)\n",
    "\t\treturn sim\n",
    "\telif method == 'Baseline_Desc_only':\n",
    "\t\thcd = highest_common_descendant((go_id1, go_id2), go)\n",
    "\t\tif hcd != 0:\n",
    "\t\t\thcd_depth = go[hcd].reldepth\n",
    "\t\t\tgo1_depth = go[go_id1].reldepth\n",
    "\t\t\tgo2_depth = go[go_id2].reldepth\n",
    "\t\t\tx = hcd_depth - go1_depth\n",
    "\t\t\ty = hcd_depth - go2_depth\n",
    "\t\t\tsv_a = Downward_Semantic_Value(go_id1, go, x)\n",
    "\t\t\tsv_b = Downward_Semantic_Value(go_id2, go, y)\n",
    "\t\t\tintersecting_terms = intersection(sv_a,sv_b)\n",
    "\t\t\tnumerator = sum([x for t in intersecting_terms for x in t]) # Sum of common terms in all paths wrt to each of the 2 terms\n",
    "\t\t\tdenominator = sum(x for y, x in sv_a) + sum(x for y, x in sv_b) #(where sv_a has 2 values for each term, second being the SV)\n",
    "\t\t\tsim_down = (numerator/denominator)\n",
    "\t\telse:\n",
    "\t\t\tsim_down = 0\n",
    "\t\treturn sim_down\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Similarity_of_Set_of_GOTerms(set1, set2, method):\n",
    "\tSim1 = []\n",
    "\tSim2 = []\n",
    "\tfor idx, goterm in enumerate(set1):\n",
    "\t\t# print (\"=========\", goterm)\n",
    "\t\tSim1.append([])\n",
    "\t\tfor goid in set2:\n",
    "\t\t\t#print (goterm , goid)\n",
    "\t\t\tSim1[idx].append((goterm, goid,(Similarity_of_Two_GOTerms(goterm, goid, go, method))))\n",
    "\tfor idx, goterm in enumerate(set2):\n",
    "\t\tSim2.append([])\n",
    "\t\tfor goid in set1:\n",
    "\t\t\t#print (goterm , goid)\n",
    "\t\t\tSim2[idx].append((goterm, goid,(Similarity_of_Two_GOTerms(goterm, goid, go, method))))\n",
    "\tsem1 = []\n",
    "\tsem2 = []\n",
    "\n",
    "\tfor index, goterm in enumerate(Sim1):\t\n",
    "\t\tsem1.append((max(Sim1[index], key=lambda x: x[2])))\n",
    "\tfor index, goterm in enumerate(Sim2):\t\n",
    "\t\tsem2.append((max(Sim2[index], key=lambda x: x[2])))\n",
    "\n",
    "\tsimilarity = (sum(x[2] for x in sem1)+ sum(x[2] for x in sem2) )/(len(set1) + len(set2))\n",
    "\t\n",
    "\treturn round(similarity, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation: Clustering, AMI/ARI Scores\n",
    "\n",
    "def Similarity_Matrix(genes, method, S_values):\n",
    "\tsim_matrix = []\n",
    "\tfor idx,gene in enumerate(genes):\n",
    "\t\tprint(gene)\n",
    "\t\tsim_matrix.append([(lambda x: Similarity_of_Set_of_GOTerms(x[1],gene[1], method, S_values))(x) for x in genes])\n",
    "\treturn sim_matrix\n",
    "\n",
    "def Agglomerative_Clustering(pathway, Genes, n_clusters, method, S_values):\n",
    "\t# Similarity Matrix\n",
    "\tdata = Similarity_Matrix(Genes, method, S_values)\n",
    "\tlength = len(data)\n",
    "\tdata1 = pd.DataFrame(data = data, index=[x[0] for x in Genes],columns=[x[0]for x in Genes])\n",
    "\t#print('similarity matrisx: ')\n",
    "\t#print(data1)\n",
    "\t#writeSim = pathway + \"_SimilarityMatrix.csv\"\n",
    "\t#data1.to_csv(writeSim)\n",
    "\tdata_matrix = []\n",
    "\tfor row in data:\n",
    "\t\tdata_matrix.append([(lambda x: 1-x)(x) for x in row])\n",
    "\tmy_data = pd.DataFrame(data = data_matrix, index=[x[0] for x in Genes],columns=[x[0]for x in Genes])\n",
    "\treturn Agglomerative(my_data,Genes, pathway, n_clusters)\n",
    "\n",
    "def Agglomerative( data, Genes, pathway, n_clusters):\n",
    "\t#model = AgglomerativeClustering(n_clusters, affinity='precomputed', linkage='complete').fit(data)\n",
    "\tmodel = AgglomerativeClustering(n_clusters, affinity='precomputed', linkage='complete').fit_predict(data)\n",
    "\t#Single linkage minimizes the distance between the closest observations of pairs of clusters.\n",
    "\tGeneNames = [gene.GeneName for gene in Genes]\n",
    "\treturn model.tolist()\n",
    "\n",
    "def ARI_Score(label_pred, labels_true):\n",
    "\treturn adjusted_rand_score(label_pred, labels_true)\n",
    "\n",
    "def AMI_Score(label_pred, labels_true):\n",
    "\treturn adjusted_mutual_info_score(label_pred, labels_true, average_method='arithmetic')\n",
    "\n",
    "def cont_matrix (y_true, y_pred):\n",
    "\tcontingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "\t# return purity\n",
    "\treturn(contingency_matrix)\n",
    "\n",
    "def purity_score(y_true, y_pred):\n",
    "\t# compute contingency matrix (also called confusion matrix)\n",
    "\tcontingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "\t#print(contingency_matrix)\n",
    "\treturn np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_id1 = 'GO:0005634'\n",
    "go_id2 = 'GO:0042579'\n",
    "go_id3 = 'GO:0005777'\n",
    "go_id4 = 'GO:0031903'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0005634 and GO:0042579 = 0.7439251158246399\n",
      "GO:0005777 and GO:0031903 = 0.6467454250637018\n"
     ]
    }
   ],
   "source": [
    "method = 'wang'\n",
    "print(go_id1,\"and\", go_id2, \"=\", Similarity_of_Two_GOTerms(go_id1, go_id2, go, method))\n",
    "print(go_id3,\"and\", go_id4, \"=\",Similarity_of_Two_GOTerms(go_id3, go_id4, go, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0005634 and GO:0042579 = 0.43452661328308995\n",
      "GO:0005777 and GO:0031903 = 0.5194065084215557\n"
     ]
    }
   ],
   "source": [
    "method = 'GOntoSim'\n",
    "Similarity_of_Two_GOTerms(go_id1, go_id2, go, method)\n",
    "Similarity_of_Two_GOTerms(go_id3, go_id4, go, method)\n",
    "print(go_id1,\"and\", go_id2, \"=\", Similarity_of_Two_GOTerms(go_id1, go_id2, go, method))\n",
    "print(go_id3,\"and\", go_id4, \"=\",Similarity_of_Two_GOTerms(go_id3, go_id4, go, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0005634 and GO:0042579 = 0.8063518717651381\n",
      "GO:0005777 and GO:0031903 = 0.7583138688114581\n"
     ]
    }
   ],
   "source": [
    "method = 'GOGO'\n",
    "Similarity_of_Two_GOTerms(go_id1, go_id2, go, method)\n",
    "Similarity_of_Two_GOTerms(go_id3, go_id4, go, method)\n",
    "print(go_id1,\"and\", go_id2, \"=\", Similarity_of_Two_GOTerms(go_id1, go_id2, go, method))\n",
    "print(go_id3,\"and\", go_id4, \"=\",Similarity_of_Two_GOTerms(go_id3, go_id4, go, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0005634 and GO:0042579 = 0.7246229452635147\n",
      "GO:0005777 and GO:0031903 = 0.627412655753726\n"
     ]
    }
   ],
   "source": [
    "method = 'Baseline'\n",
    "Similarity_of_Two_GOTerms(go_id1, go_id2, go, method)\n",
    "Similarity_of_Two_GOTerms(go_id3, go_id4, go, method)\n",
    "print(go_id1,\"and\", go_id2, \"=\", Similarity_of_Two_GOTerms(go_id1, go_id2, go, method))\n",
    "print(go_id3,\"and\", go_id4, \"=\",Similarity_of_Two_GOTerms(go_id3, go_id4, go, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0005634 and GO:0042579 = 0.8690532265661799\n",
      "GO:0005777 and GO:0031903 = 0.9008819823603528\n"
     ]
    }
   ],
   "source": [
    "method = 'Baseline_LCA'\n",
    "Similarity_of_Two_GOTerms(go_id1, go_id2, go, method)\n",
    "Similarity_of_Two_GOTerms(go_id3, go_id4, go, method)\n",
    "print(go_id1,\"and\", go_id2, \"=\", Similarity_of_Two_GOTerms(go_id1, go_id2, go, method))\n",
    "print(go_id3,\"and\", go_id4, \"=\",Similarity_of_Two_GOTerms(go_id3, go_id4, go, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO:0005634 and GO:0042579 = 0.36231147263175734\n",
      "GO:0005777 and GO:0031903 = 0.38267184511824226\n"
     ]
    }
   ],
   "source": [
    "method = 'Baseline_Desc'\n",
    "Similarity_of_Two_GOTerms(go_id1, go_id2, go, method)\n",
    "Similarity_of_Two_GOTerms(go_id3, go_id4, go, method)\n",
    "print(go_id1,\"and\", go_id2, \"=\", Similarity_of_Two_GOTerms(go_id1, go_id2, go, method))\n",
    "print(go_id3,\"and\", go_id4, \"=\",Similarity_of_Two_GOTerms(go_id3, go_id4, go, method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
